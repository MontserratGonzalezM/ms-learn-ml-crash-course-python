{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    },
    "colab": {
      "name": "10. Convolutional Neural Networks - Python.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MontserratGonzalezM/ms-learn-ml-crash-course-python/blob/master/m10.%20Convolutional%20Neural%20Networks%20-%20Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQ_sjVaKjCgh"
      },
      "source": [
        "Convolutional Neural Networks\n",
        "======\n",
        "\n",
        "Convolutional neural networks (CNNs) are a class of deep neural networks, most commonly used in computer vision applications.\n",
        "\n",
        "Convolutional refers the network pre-processing data for you - traditionally this pre-processing was performed by data scientists. The neural network can learn how to do pre-processing *itself* by applying filters for things such as edge detection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIOdSFw-jCgk"
      },
      "source": [
        "Step 1\n",
        "-----\n",
        "\n",
        "In this exercise we will train a CNN to recognise handwritten digits, using the MNIST digit dataset.\n",
        "\n",
        "This is a very common exercise and data set to learn from.\n",
        "\n",
        "Let's start by loading our dataset and setting up our train, validation, and test sets.\n",
        "\n",
        "#### Run the code below to import our required libraries and set up the graphing features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JEj6-YmYjCgm",
        "outputId": "58001cc2-b2a4-44f5-e362-3b6305ea8a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Run this!\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "print('keras using %s backend'%keras.backend.backend())\n",
        "import matplotlib.pyplot as graph\n",
        "%matplotlib inline\n",
        "graph.rcParams['figure.figsize'] = (15,5)\n",
        "graph.rcParams[\"font.family\"] = 'DejaVu Sans'\n",
        "graph.rcParams[\"font.size\"] = '12'\n",
        "graph.rcParams['image.cmap'] = 'rainbow'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras using tensorflow backend\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiGefEJWjCgz"
      },
      "source": [
        "### In the cell below replace:\n",
        "#### 1. `<addTrainX>` with `train_X`\n",
        "#### 2. `<addTrainY>` with `train_Y`\n",
        "#### 3. `<addValidX>` with `valid_X`\n",
        "#### 4. `<addValidY>` with `valid_Y`\n",
        "#### 5. `<addTextX>` with `test_X`\n",
        "#### 6. `<addTextY>` with `test_Y`\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "klrLqBfdjCg0",
        "outputId": "813739d1-04c1-4355-beb3-c5f811482be0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "# Here we import the dataset, and split it into the training, validation, and test sets.\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# This is our training data, with 6400 samples.\n",
        "###\n",
        "# REPLACE <addTrainX> WITH train_X AND <addTrainY> WITH train_Y\n",
        "###\n",
        "train_X = mnist.load_data()[0][0][:6400].astype('float32')\n",
        "train_Y = mnist.load_data()[0][1][:6400]\n",
        "###\n",
        "\n",
        "# This is our validation data, with 1600 samples.\n",
        "###\n",
        "# REPLACE <addValidX> WITH valid_X AND <addValidY> WITH valid_Y\n",
        "###\n",
        "valid_X = mnist.load_data()[1][0][:1600].astype('float32')\n",
        "valid_Y = mnist.load_data()[1][1][:1600]\n",
        "###\n",
        "\n",
        "# This is our test data, with 2000 samples.\n",
        "###\n",
        "# REPLACE <addTextX> WITH test_X AND <addTextY> WITH test_Y\n",
        "###\n",
        "test_X = mnist.load_data()[1][0][-2000:].astype('float32')\n",
        "test_Y = mnist.load_data()[1][1][-2000:]\n",
        "###\n",
        "\n",
        "print('train_X:', train_X.shape, end = '')\n",
        "print(', train_Y:', train_Y.shape)\n",
        "print('valid_X:', valid_X.shape, end = '')\n",
        "print(', valid_Y:', valid_Y.shape)\n",
        "print('test_X:', test_X.shape, end = '')\n",
        "print(', test_Y:', test_Y.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "train_X: (6400, 28, 28), train_Y: (6400,)\n",
            "valid_X: (1600, 28, 28), valid_Y: (1600,)\n",
            "test_X: (2000, 28, 28), test_Y: (2000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlazVqp7jCg6"
      },
      "source": [
        "So we have 6400 training samples, 1600 validation samples, and 2000 test samples.\n",
        "\n",
        "Each sample is an greyscale image - 28 pixels wide and 28 pixels high. Each pixel is really a number from 0 to 255 - 0 being fully black, 255 being fully white. When we graph the 28x28 numbers, we can see the image.\n",
        "\n",
        "Let's have a look at one of our samples.\n",
        "\n",
        "#### Replace `<addSample>` with `train_X[0]` (you can change 0 to any number between 0 and 6400 if you like)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RJo0txH-jCg7",
        "outputId": "02ba6c18-e851-4cd4-a70f-31be4303e0a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "###\n",
        "# REPLACE THE <addSample> BELOW WITH train_X[0] OR ANOTHER SAMPLE e.g. train_X[1] or train_X[2]\n",
        "###\n",
        "graph.imshow(train_X[0], cmap = 'gray', interpolation = 'nearest')\n",
        "###\n",
        "\n",
        "graph.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3316e58beadd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# REPLACE THE <addSample> BELOW WITH train_X[0] OR ANOTHER SAMPLE e.g. train_X[1] or train_X[2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'gray'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2651\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2652\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msanitize_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1567\u001b[0m         \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_sig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m                 \u001b[0;34mf\"%(removal)s.  If any parameter follows {name!r}, they \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m                 f\"should be pass as keyword, not positionally.\")\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5624\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5626\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5627\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5628\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    697\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m    698\u001b[0m             raise TypeError(\"Invalid shape {} for image data\"\n\u001b[0;32m--> 699\u001b[0;31m                             .format(self._A.shape))\n\u001b[0m\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Invalid shape (28, 28, 1) for image data"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hv0gmjokjChG"
      },
      "source": [
        "Step 2\n",
        "---\n",
        "\n",
        "The neural network will use the 28x28 values of each image to predict what each image represents.\n",
        "\n",
        "As each value is between 0 and 255, we'll scale the values down by dividing by 255 (this makes it faster for the Neural Network to train).\n",
        "\n",
        "We need to reshape our data to get it working well with our neural network. \n",
        "\n",
        "### In the cell below replace:\n",
        "#### 1. `<addRehape>` with `reshape`\n",
        "#### 2. `<completeCalculation>` with `/255`\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pzRHBNakjChH",
        "outputId": "bc13686c-d258-4ade-9275-36c161bb9925",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# First off, let's reshape our X sets so that they fit the convolutional layers.\n",
        "\n",
        "# This gets the image dimensions - 28\n",
        "dim = train_X[0].shape[0]\n",
        "\n",
        "###\n",
        "# REPLACE THE <addRehape> BELOW WITH reshape\n",
        "###\n",
        "train_X = train_X.reshape(train_X.shape[0], dim, dim, 1)\n",
        "valid_X = valid_X.reshape(valid_X.shape[0], dim, dim, 1)\n",
        "test_X = test_X.reshape(test_X.shape[0], dim, dim, 1)\n",
        "###\n",
        "\n",
        "# Next up - feature scaling.\n",
        "# We scale the values so they are between 0 and 1, instead of 0 and 255.\n",
        "\n",
        "###\n",
        "# REPLACE THE <completeCalculation> BELOW WITH /255\n",
        "###\n",
        "train_X = train_X /255\n",
        "valid_X = valid_X /255\n",
        "test_X = test_X /255\n",
        "###\n",
        "\n",
        "\n",
        "# Now we print the label for the first example\n",
        "print(train_Y[0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_w11gaijChK"
      },
      "source": [
        "Expected output:  \n",
        "`5`\n",
        "\n",
        "The label is a number - the number we see when we view the image.\n",
        "\n",
        "We need represent this number as a one-hot vector, so the neural network knows it is a category.\n",
        "\n",
        "Keras can convert these labels into one-hot vectors easily with the function - `to_categorical`\n",
        "\n",
        "#### Replace `<addCategorical>` with `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Wu9ieDNkjChK",
        "outputId": "bb9ebd4a-3d71-43c5-8680-1413369d4a21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "###\n",
        "# REPLACE THE <addCategorical> BELOW WITH to_categorical\n",
        "###\n",
        "train_Y = keras.utils.to_categorical(train_Y, 10)\n",
        "valid_Y = keras.utils.to_categorical(valid_Y, 10)\n",
        "test_Y = keras.utils.to_categorical(test_Y, 10)\n",
        "###\n",
        "\n",
        "# 10 being the number of categories (numbers 0 to 9)\n",
        "\n",
        "print(train_Y[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIq9nN2WjChO"
      },
      "source": [
        "Expected output:  \n",
        "`[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]`\n",
        "\n",
        "Step 3\n",
        "-----\n",
        "\n",
        "All ready! Time to build another neural network.\n",
        "\n",
        "#### Replace `<addSequential>` with `Sequential()` and run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kSR4dt-3jChQ"
      },
      "source": [
        "# Sets a randomisation seed for replicatability.\n",
        "np.random.seed(6)\n",
        "\n",
        "###\n",
        "# REPLACE THE <addSequential> BELOW WITH Sequential() (don't forget the () )\n",
        "###\n",
        "model = Sequential()\n",
        "###"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FbPNXKBjChV"
      },
      "source": [
        "The __Convolutional__ in Convolutional Neural Networks refers the pre-processing the network can do itself.\n",
        "\n",
        "#### Replace `<addConv2d>` with `Conv2D`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-ep1hUqAjChW"
      },
      "source": [
        "###\n",
        "# REPLACE THE <addConv2D> BELOW WITH Conv2D\n",
        "###\n",
        "model.add(Conv2D(28, kernel_size = (3, 3), activation = 'relu', input_shape = (dim, dim, 1)))\n",
        "model.add(Conv2D(56, (3, 3), activation = 'relu'))\n",
        "###"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqiTcF76jChZ"
      },
      "source": [
        "Next up we'll:\n",
        "* Add pooling layers.\n",
        "* Apply dropout.\n",
        "* Flatten the data to a vector (the output of step 2 is a vector).\n",
        "\n",
        "### In the cell below replace:\n",
        "#### 1. `<addMaxPooling2D>` with `MaxPooling2D`\n",
        "#### 2. `<addDropout>` with `Dropout`\n",
        "#### 3. `<addFlatten>` with `Flatten()`\n",
        "\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wu44zOGljChZ"
      },
      "source": [
        "# Pooling layers help speed up training time and make features it detects more robust.\n",
        "# They act by downsampling the data - reducing the data size and complexity.\n",
        "\n",
        "###\n",
        "# REPLACE THE <addMaxPooling2D> BELOW WITH MaxPooling2D\n",
        "###\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "###\n",
        "\n",
        "# Dropout is a technique to help prevent overfitting\n",
        "# It makes nodes 'dropout' - turning them off randomly.\n",
        "\n",
        "###\n",
        "# REPLACE THE <addDropout> BELOW WITH Dropout\n",
        "###\n",
        "model.add(Dropout(0.125))\n",
        "###\n",
        "\n",
        "\n",
        "###\n",
        "# REPLACE THE <addFlatten> BELOW WITH Flatten()\n",
        "###\n",
        "model.add(Flatten())\n",
        "###"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBSQg8jNjChd"
      },
      "source": [
        "#### Replace `<updateHere>` with 10 and run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NR0ECMJCjChd"
      },
      "source": [
        "# Dense layers perform classification - we have extracted the features with the convolutional pre-processing\n",
        "model.add(Dense(128, activation='relu'))\n",
        "\n",
        "# More dropout!\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Next is our output layer\n",
        "# Softmax outputs the probability for each category\n",
        "###\n",
        "# REPLACE <updateHere> BELOW WITH 10, THE NUMBER OF CLASSES (DIGITS 0 TO 9)\n",
        "###\n",
        "model.add(Dense(10, activation=tf.nn.softmax))\n",
        "###\n",
        "\n",
        "# And finally, we compile.\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adamax', metrics=['accuracy'])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQv-uVMpjChi"
      },
      "source": [
        "Step 4\n",
        "-----\n",
        "\n",
        "Let's train it!\n",
        "\n",
        "### In the cell below replace:\n",
        "#### 1. `<addTrainX>` with `train_X `\n",
        "#### 2. `<addTrainY>` with `train_Y`\n",
        "#### 3. `<addValidX>` with `valid_X`\n",
        "#### 4. `<addValidY>` with `valid_Y`\n",
        "#### 5. `<addEvaluate>` with `evaluate`\n",
        "\n",
        "#### and then __run the code__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "XDaB4Y53jChi",
        "outputId": "58dc364a-4771-424e-bcbe-5165ba03e7dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        }
      },
      "source": [
        "###\n",
        "# REPLACE THE <addTrainX> WITH train_X, <addTrainY> WITH train_Y, <addValidX> WITH valid_X, AND <addValidY> WITH valid_Y\n",
        "###\n",
        "training_stats = model.fit(train_X, train_Y, batch_size = 128, epochs = 12, verbose = 1, validation_data = (valid_X, valid_Y))\n",
        "###\n",
        "\n",
        "###\n",
        "# REPLACE THE <addEvaluate> BELOW WITH evaluate\n",
        "###\n",
        "evaluation = model.evaluate(test_X, test_Y, verbose=0)\n",
        "###\n",
        "\n",
        "print('Test Set Evaluation: loss = %0.6f, accuracy = %0.2f' %(evaluation[0], 100 * evaluation[1]))\n",
        "\n",
        "# We can plot our training statistics to see how it developed over time\n",
        "accuracy, = graph.plot(training_stats.history['accuracy'], label = 'Accuracy')\n",
        "training_loss, = graph.plot(training_stats.history['loss'], label = 'Training Loss')\n",
        "graph.legend(handles = [accuracy, training_loss])\n",
        "loss = np.array(training_stats.history['loss'])\n",
        "xp = np.linspace(0,loss.shape[0],10 * loss.shape[0])\n",
        "graph.plot(xp, np.full(xp.shape, 1), c = 'k', linestyle = ':', alpha = 0.5)\n",
        "graph.plot(xp, np.full(xp.shape, 0), c = 'k', linestyle = ':', alpha = 0.5)\n",
        "graph.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "50/50 [==============================] - 14s 289ms/step - loss: 0.0474 - accuracy: 0.9875 - val_loss: 0.1137 - val_accuracy: 0.9625\n",
            "Epoch 2/12\n",
            "50/50 [==============================] - 14s 281ms/step - loss: 0.0457 - accuracy: 0.9880 - val_loss: 0.1198 - val_accuracy: 0.9600\n",
            "Epoch 3/12\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0362 - accuracy: 0.9900 - val_loss: 0.1187 - val_accuracy: 0.9619\n",
            "Epoch 4/12\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0328 - accuracy: 0.9906 - val_loss: 0.1078 - val_accuracy: 0.9656\n",
            "Epoch 5/12\n",
            "50/50 [==============================] - 14s 279ms/step - loss: 0.0280 - accuracy: 0.9914 - val_loss: 0.1105 - val_accuracy: 0.9656\n",
            "Epoch 6/12\n",
            "50/50 [==============================] - 14s 278ms/step - loss: 0.0265 - accuracy: 0.9933 - val_loss: 0.1090 - val_accuracy: 0.9669\n",
            "Epoch 7/12\n",
            "50/50 [==============================] - 14s 280ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.1052 - val_accuracy: 0.9656\n",
            "Epoch 8/12\n",
            "50/50 [==============================] - 14s 286ms/step - loss: 0.0199 - accuracy: 0.9952 - val_loss: 0.1131 - val_accuracy: 0.9663\n",
            "Epoch 9/12\n",
            "50/50 [==============================] - 14s 283ms/step - loss: 0.0212 - accuracy: 0.9950 - val_loss: 0.1155 - val_accuracy: 0.9638\n",
            "Epoch 10/12\n",
            "50/50 [==============================] - 16s 318ms/step - loss: 0.0186 - accuracy: 0.9945 - val_loss: 0.1072 - val_accuracy: 0.9681\n",
            "Epoch 11/12\n",
            "50/50 [==============================] - 15s 298ms/step - loss: 0.0155 - accuracy: 0.9950 - val_loss: 0.1093 - val_accuracy: 0.9650\n",
            "Epoch 12/12\n",
            "50/50 [==============================] - 14s 284ms/step - loss: 0.0146 - accuracy: 0.9967 - val_loss: 0.1093 - val_accuracy: 0.9650\n",
            "Test Set Evaluation: loss = 0.061069, accuracy = 98.60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bof9OG0WjChl"
      },
      "source": [
        "## Step 5\n",
        "\n",
        "Let's test it on a new sample that it hasn't seen, and see how it classifies it!\n",
        "\n",
        "#### Replace `<addNumber>` with any number between 0 and 1999, then run the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "llu74luzjChm",
        "outputId": "b6c815cc-872d-46f0-9cdd-9a64c58c704a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "###\n",
        "# REPLACE THE <addNumber> WITH ANY NUMBER BETWEEN 0 AND 1999\n",
        "###\n",
        "sample = test_X[0].reshape(dim, dim)\n",
        "###\n",
        "\n",
        "graph.imshow(sample, cmap = 'gray', interpolation = 'nearest')\n",
        "graph.show()\n",
        "\n",
        "prediction = model.predict(sample.reshape(1, dim, dim, 1))\n",
        "print('prediction: %i' %(np.argmax(prediction)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "prediction: 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fj0l9jMPjCho"
      },
      "source": [
        "How is the prediction? Does it look right?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVVdzH86jChp"
      },
      "source": [
        "Conclusion\n",
        "------\n",
        "\n",
        "Congratulations! We've built a convolutional neural network that is able to recognise handwritten digits with very high accuracy.\n",
        "\n",
        "CNN's are very complex - you're not expected to understand everything (or most things) we covered here. They take a lot of time and practise to properly understand each aspect of them.\n",
        "\n",
        "Here we used:  \n",
        "* __Feature scaling__ - reducing the range of the values. This helps improve training time.\n",
        "* __Convolutional layers__ - network layers that pre-process the data for us. These apply filters to extract features for the neural network to analyze.\n",
        "* __Pooling layers__ - part of the Convolutional layers. They apply filters downsample the data - extracting features.\n",
        "* __Dropout__ - a regularization technique to help prevent overfitting.\n",
        "* __Dense layers__ - neural network layers which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers.\n",
        "* __Softmax__ - an activation function which outputs the probability for each category."
      ]
    }
  ]
}